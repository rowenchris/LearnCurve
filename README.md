# LearnCurve ğŸ“ˆ

**An interactive visualization of how neural networks learn**

Watch a neural network learn to approximate any mathematical function in real-time. No installation required â€“ runs entirely in your browser!

## ğŸ¯ Try It Now

**[Launch LearnCurve â†’](https://YOUR_USERNAME.github.io/LearnCurve/)**

*(Update this link after deployment)*

---

## What You'll See

| Green Curve | Blue Curve |
|-------------|------------|
| Target function f(x) | Network's prediction Å·(x) |
| What we want to learn | What the network currently outputs |

**Goal:** Make blue match green by training the network!

---

## âœ¨ Features

### ğŸ® Interactive Controls
- **Target Function**: Type any math expression (`x*x`, `sin(x)`, `abs(x)`, etc.)
- **Learning Rate**: Control step size (bigger = faster but unstable)
- **Optimizer**: Compare Simple, Momentum, and Adam algorithms
- **Noise**: Test robustness with noisy training data

### ğŸ§  Network Design
- Adjust hidden layers (1-3) and neurons (2-10)
- Switch activation functions (ReLU, Tanh, Sigmoid)
- Watch weights update in real-time

### ğŸ“Š Visualization
- **Fit Plot**: Prediction curve approaching target
- **Training Trace**: Loss decreasing over time
- **Equations**: The math behind forward pass & backpropagation

### ğŸ”¬ Comparison Mode
- Save two training runs with different settings
- Compare learning curves side-by-side
- Discover: Which configuration learns faster?

---

## ğŸ“ Who Is This For?

Students learning machine learning who have:
- âœ… Basic algebra
- âœ… Familiarity with calculus (chain rule)
- âœ… Curiosity about how AI learns!

### Concepts Demonstrated
1. **Forward Pass** â€“ How inputs flow through the network
2. **Loss Function** â€“ Measuring prediction error
3. **Backpropagation** â€“ Computing gradients via chain rule
4. **Gradient Descent** â€“ Adjusting weights to minimize loss

---

## ğŸ§ª Suggested Experiments

| Experiment | What You'll Learn |
|------------|-------------------|
| Train on `x*x` | Basic quadratic fitting |
| Try `sin(x)` | Networks can learn periodic functions |
| Add noise (0.3) | Robustness to noisy data |
| Compare Adam vs Simple | Why adaptive optimizers help |
| 1 layer vs 3 layers | Depth vs training speed |

---

## ğŸ› ï¸ Technical Details

- **Pure HTML/CSS/JavaScript** â€“ zero dependencies
- **No build step** â€“ just open the file
- **~3000 lines** of self-contained code
- **Works on mobile** and desktop browsers

---

## ğŸ¤ Credits

Built by **Chris Rowen** and **Claude 4.5 Opus** (Anthropic)

---

## ğŸ“„ License

MIT License â€“ Use, modify, and share freely!

---

â­ **Star this repo if you find it useful for teaching or learning!**
